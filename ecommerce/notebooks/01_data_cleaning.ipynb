{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af0ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.helpers:Plotting style configured: seaborn, notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.helpers:Plotting style configured: seaborn, notebook\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading raw data...\n",
      "Customers: (500, 8)\n",
      "Products: (1000, 10)\n",
      "Transactions: (1000, 7)\n",
      "üîç Initial Data Validation\n",
      "==================================================\n",
      "üîÑ Converting data types...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.helpers:Plotting style configured: seaborn, notebook\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading raw data...\n",
      "Customers: (500, 8)\n",
      "Products: (1000, 10)\n",
      "Transactions: (1000, 7)\n",
      "üîç Initial Data Validation\n",
      "==================================================\n",
      "üîÑ Converting data types...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'signup_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\makvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3790\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3792\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:152\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:181\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'signup_date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîÑ Converting data types...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Convert dates\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m customers[\u001b[33m'\u001b[39m\u001b[33msignup_date\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43mcustomers\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msignup_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m    106\u001b[39m transactions[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(transactions[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# Ensure numeric columns are proper types\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\makvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   3892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m3893\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3894\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   3895\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\makvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3793\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3794\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3795\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3796\u001b[39m     ):\n\u001b[32m   3797\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3798\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3799\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3800\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3801\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3802\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3803\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'signup_date'"
     ]
    }
   ],
   "source": [
    "# E-commerce Data Cleaning and Preparation\n",
    "## Project Overview\n",
    "\"\"\"\n",
    "This notebook focuses on cleaning and preparing e-commerce data for analysis. We'll handle missing values, data type conversions, and create a clean dataset for further analysis.\n",
    "\n",
    "### Steps:\n",
    "1. Data Loading and Initial Exploration\n",
    "2. Data Quality Assessment\n",
    "    \"3. Handling Missing Values\\n\",\n",
    "    \"4. Data Type Conversions\\n\",\n",
    "    \"5. Feature Engineering\\n\",\n",
    "    \"6. Data Validation\\n\",\n",
    "    \"7. Saving Cleaned Data\"\n",
    "  \"\"\" \n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Add shared modules to path\n",
    "sys.path.append('C:/Data Science Projects/data-engineering-portfolio/shared')\n",
    "\n",
    "# Fix for missing 'shared' module\n",
    "# If 'shared' is a local folder, ensure it exists and is in the correct path.\n",
    "# If it's a package, install it using pip.\n",
    "try:\n",
    "    from shared.utils.helpers import validate_data, VisualizationHelper\n",
    "except ModuleNotFoundError:\n",
    "    # Try installing if it's a pip package (uncommon for 'shared')\n",
    "    # %pip install shared\n",
    "    print(\"‚ö†Ô∏è 'shared' module not found. Please ensure '../../shared' exists and contains 'utils/helpers.py'.\")\n",
    "    # Optionally, raise the error to stop execution\n",
    "    raise\n",
    "\n",
    "# Setup plotting\n",
    "VisualizationHelper.setup_plotting()\n",
    "%matplotlib inline\n",
    "# Load raw data\\n\",\n",
    "print(\"üìÇ Loading raw data...\")\n",
    "\n",
    "customers = pd.read_csv('../data/raw/ecommerce_customers.csv')\n",
    "products = pd.read_csv('../data/raw/ecommerce_products.csv') \n",
    "transactions = pd.read_csv('../data/raw/ecommerce_transactions.csv')\n",
    "\n",
    "print(f\"Customers: {customers.shape}\")\n",
    "print(f\"Products: {products.shape}\")\n",
    "print(f\"Transactions: {transactions.shape}\")\n",
    "# Initial data validation\\n\",\n",
    "print(\"üîç Initial Data Validation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "validate_data(customers, \"Customers\")\n",
    "validate_data(products, \"Products\")\n",
    "validate_data(transactions, \"Transactions\")\n",
    "\n",
    "print(\"üîÑ Converting data types...\")\n",
    "\n",
    "# Convert dates\n",
    "customers['signup_date'] = pd.to_datetime(customers['signup_date'])\n",
    "transactions['date'] = pd.to_datetime(transactions['date'])\n",
    "\n",
    "# Ensure numeric columns are proper types\n",
    "products['price'] = pd.to_numeric(products['price'], errors='coerce')\n",
    "products['cost'] = pd.to_numeric(products['cost'], errors='coerce')\n",
    "transactions['quantity'] = pd.to_numeric(transactions['quantity'], errors='coerce')\n",
    "\n",
    "print(\"‚úÖ Data types converted\")\n",
    "print(\"üîß Handling missing values...\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values before cleaning:\")\n",
    "print(\"Customers:\", customers.isnull().sum().sum())\n",
    "print(\"Products:\", products.isnull().sum().sum())\n",
    "print(\"Transactions:\", transactions.isnull().sum().sum())\n",
    "\n",
    "# Fill missing values\n",
    "customers_clean = customers.dropna()\n",
    "products_clean = products.fillna({'category': 'Unknown', 'price': products['price'].median()})\n",
    "transactions_clean = transactions.dropna()\n",
    "\n",
    "print(\"\\n‚úÖ Missing values handled\")\n",
    "print(\"üßπ Removing duplicates...\")\n",
    "\n",
    "print(f\"Customers before: {len(customers_clean)}\")\n",
    "customers_clean = customers_clean.drop_duplicates()\n",
    "print(f\"Customers after: {len(customers_clean)}\")\n",
    "\n",
    "print(f\"Products before: {len(products_clean)}\")\n",
    "products_clean = products_clean.drop_duplicates()\n",
    "print(f\"Products after: {len(products_clean)}\")\n",
    "\n",
    "print(f\"Transactions before: {len(transactions_clean)}\")\n",
    "transactions_clean = transactions_clean.drop_duplicates()\n",
    "print(f\"Transactions after: {len(transactions_clean)}\")\n",
    "# Feature engineering\\n\",\n",
    "print(\"üéØ Creating new features...\")\n",
    "\n",
    "# Calculate customer tenure (days since signup)\n",
    "latest_date = transactions_clean['date'].max()\n",
    "customers_clean['tenure_days'] = (latest_date - customers_clean['signup_date']).dt.days\n",
    "\n",
    "# Create price segments for products\n",
    "products_clean['price_segment'] = pd.cut(products_clean['price'], \n",
    "                                       bins=[0, 50, 100, 200, 500],\n",
    "                                       labels=['Budget', 'Mid-range', 'Premium', 'Luxury'])\n",
    "\n",
    "# Add profit margin to products\n",
    "products_clean['profit_margin'] = ((products_clean['price'] - products_clean['cost']) / products_clean['price']) * 100\n",
    "\n",
    "print(\"‚úÖ New features created\")\n",
    "# Create enriched transactions dataset\\n\",\n",
    "print(\"üîó Creating enriched transactions dataset...\")\n",
    "\n",
    "enriched_transactions = transactions_clean.merge(\n",
    "    customers_clean[['customer_id', 'location', 'tier', 'tenure_days']], \n",
    "    on='customer_id', \n",
    "    how='left'\n",
    ").merge(\n",
    "    products_clean[['product_id', 'product_name', 'category', 'price', 'price_segment', 'profit_margin']], \n",
    "    on='product_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate business metrics\n",
    "enriched_transactions['revenue'] = enriched_transactions['quantity'] * enriched_transactions['price']\n",
    "enriched_transactions['profit'] = enriched_transactions['quantity'] * (enriched_transactions['price'] * (enriched_transactions['profit_margin'] / 100))\n",
    "\n",
    "# Add time-based features\n",
    "enriched_transactions['month'] = enriched_transactions['date'].dt.to_period('M')\n",
    "enriched_transactions['day_of_week'] = enriched_transactions['date'].dt.day_name()\n",
    "enriched_transactions['is_weekend'] = enriched_transactions['date'].dt.dayofweek >= 5\n",
    "print(f\"‚úÖ Enriched transactions created: {enriched_transactions.shape}\")\n",
    "# Data validation after cleaning\\n\",\n",
    "print(\"üîç Final Data Validation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "validate_data(customers_clean, \"Cleaned Customers\")\n",
    "validate_data(products_clean, \"Cleaned Products\")\n",
    "validate_data(enriched_transactions, \"Enriched Transactions\")\n",
    "\n",
    "# Check data quality metrics\n",
    "print(\"\\nüìä Data Quality Summary:\")\n",
    "print(f\"Total Customers: {len(customers_clean)}\")\n",
    "print(f\"Total Products: {len(products_clean)}\")\n",
    "print(f\"Total Transactions: {len(enriched_transactions)}\")\n",
    "print(f\"Total Revenue: ${enriched_transactions['revenue'].sum():,.2f}\")\n",
    "print(f\"Date Range: {enriched_transactions['date'].min()} to {enriched_transactions['date'].max()}\")\n",
    "# Save cleaned data\\n\",\n",
    "print(\"üíæ Saving cleaned data...\")\n",
    "\n",
    "customers_clean.to_csv('../data/processed/customers_clean.csv', index=False)\n",
    "products_clean.to_csv('../data/processed/products_clean.csv', index=False)\n",
    "enriched_transactions.to_csv('../data/processed/enriched_transactions.csv', index=False)\n",
    "print(\"‚úÖ Cleaned data saved to data/processed/\")\n",
    "\n",
    "# Create a basic summary for quick analysis\n",
    "summary_stats = {\n",
    "    'total_customers': len(customers_clean),\n",
    "    'total_products': len(products_clean),\n",
    "    'total_transactions': len(enriched_transactions),\n",
    "    'total_revenue': enriched_transactions['revenue'].sum(),\n",
    "    'avg_transaction_value': enriched_transactions['revenue'].mean(),\n",
    "    'date_range_start': enriched_transactions['date'].min(),\n",
    "    'date_range_end': enriched_transactions['date'].max()\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary_stats])\n",
    "summary_df.to_csv('../data/processed/summary_statistics.csv', index=False)\n",
    "\n",
    "print(\"\\nüéâ Data cleaning completed successfully!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run 02_eda.ipynb for exploratory data analysis\")\n",
    "print(\"2. Check the processed data in data/processed/\")\n",
    "print(\"3. Proceed to feature engineering and modeling\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
