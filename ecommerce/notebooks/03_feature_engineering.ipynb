{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b38a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E-commerce Feature Engineering  \n",
    "\n",
    "## Project Overview\n",
    "\"\"\"\n",
    "This notebook focuses on advanced feature engineering techniques to create meaningful features for machine learning models and business analysis.\n",
    "\n",
    "### Feature Engineering Categories:\n",
    "    \"1. **Temporal Features** - Time-based patterns and trends  \n",
    "    \"2. **Customer Behavioral Features** - RFM analysis and customer patterns  \n",
    "    \"3. **Product Features** - Product performance and characteristics  \n",
    "    \"4. **Transactional Features** - Purchase patterns and basket analysis  \n",
    "    \"5. **Geographic Features** - Location-based insights  \n",
    "    \"6. **Advanced ML Features** - Features for predictive modeling  \n",
    "    \"7. **Feature Selection & Validation** - Identifying most important features\"\n",
    " \"\"\"\n",
    " # Import libraries\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "from datetime import datetime, timedelta  \n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder  \n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression  \n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')  \n",
    " \n",
    "# Setup  \n",
    "plt.style.use('seaborn-v0_8')  \n",
    "sns.set_palette(\"husl\")  \n",
    "pd.set_option('display.max_columns', None)  \n",
    "print(\"ğŸ”§ Feature Engineering Started...\")\n",
    "# Load processed data  \n",
    "print(\"ğŸ“‚ Loading data...\")  \n",
    "transactions = pd.read_csv('../data/processed/enriched_transactions.csv')  \n",
    "customers = pd.read_csv('../data/processed/customers_clean.csv')  \n",
    "products = pd.read_csv('../data/processed/products_clean.csv')  \n",
    "\n",
    "# Convert date columns  \n",
    "transactions['date'] = pd.to_datetime(transactions['date'])  \n",
    "customers['signup_date'] = pd.to_datetime(customers['signup_date'])  \n",
    "print(f\"âœ… Data loaded: Transactions {transactions.shape}, Customers {customers.shape}, Products {products.shape}\") \n",
    "## 1. Temporal Feature Engineering\"\n",
    "print(\"â° TEMPORAL FEATURE ENGINEERING\")  \n",
    "print(\"=\" * 50)  \n",
    " \n",
    "# Extract comprehensive time-based features  \n",
    "transactions_fe = transactions.copy()  \n",
    " \n",
    "# Basic date features  \n",
    "transactions_fe['year'] = transactions_fe['date'].dt.year  \n",
    "transactions_fe['month'] = transactions_fe['date'].dt.month  \n",
    "transactions_fe['quarter'] = transactions_fe['date'].dt.quarter  \n",
    "transactions_fe['week'] = transactions_fe['date'].dt.isocalendar().week  \n",
    "transactions_fe['day'] = transactions_fe['date'].dt.day  \n",
    "transactions_fe['day_of_week'] = transactions_fe['date'].dt.dayofweek  \n",
    "transactions_fe['day_of_year'] = transactions_fe['date'].dt.dayofyear  \n",
    "transactions_fe['is_weekend'] = transactions_fe['date'].dt.dayofweek >= 5  \n",
    "transactions_fe['is_month_start'] = transactions_fe['date'].dt.is_month_start  \n",
    "transactions_fe['is_month_end'] = transactions_fe['date'].dt.is_month_end  \n",
    "\n",
    "# Seasonal features  \n",
    "transactions_fe['season'] = transactions_fe['month'].apply(  \n",
    "    lambda x: 'Winter' if x in [12, 1, 2] else  \n",
    "                 'Spring' if x in [3, 4, 5] else  \n",
    "                 'Summer' if x in [6, 7, 8] else 'Fall'  \n",
    "    )  \n",
    "\n",
    "# Holiday periods (simplified)  \n",
    "def get_holiday_period(month, day):  \n",
    "    if month == 12 and day >= 15:  # Christmas season  \n",
    "        return 'Holiday'  \n",
    "    elif month == 1 and day <= 7:  # New Year  \n",
    "        return 'Holiday'  \n",
    "    elif month == 7 and day == 4:  # Independence Day  \n",
    "        return 'Holiday'  \n",
    "    else:  \n",
    "        return 'Regular'  \n",
    "   \n",
    "transactions_fe['holiday_period'] = transactions_fe.apply(  \n",
    "    lambda x: get_holiday_period(x['month'], x['day']), axis=1  \n",
    "    )  \n",
    "   \n",
    "# Time of day features (assuming we had hour data)  \n",
    "# For now, we'll create synthetic time patterns  \n",
    "np.random.seed(42)  \n",
    "transactions_fe['hour'] = np.random.randint(0, 24, len(transactions_fe))  \n",
    "transactions_fe['time_of_day'] = pd.cut(transactions_fe['hour'],   \n",
    "                                       bins=[0, 6, 12, 18, 24],   \n",
    "                                       labels=['Night', 'Morning', 'Afternoon', 'Evening'],  \n",
    "                                       include_lowest=True)  \n",
    "print(\"âœ… Temporal features created:\")  \n",
    "print(f\"   â€¢ Date components (year, month, quarter, week, day)\")  \n",
    "print(f\"   â€¢ Day of week and year\")  \n",
    "print(f\"   â€¢ Weekend and month boundary flags\")  \n",
    "print(f\"   â€¢ Seasonal classification\")  \n",
    "print(f\"   â€¢ Holiday period identification\")  \n",
    "print(f\"   â€¢ Time of day segments\")\n",
    "# Analyze temporal patterns  \n",
    "print(\"ğŸ“Š Temporal Feature Analysis:\")  \n",
    " \n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))  \n",
    " \n",
    "# Revenue by season  \n",
    "season_revenue = transactions_fe.groupby('season')['revenue'].sum()  \n",
    "axes[0,0].bar(season_revenue.index, season_revenue.values, color=['lightblue', 'lightgreen', 'gold', 'lightcoral'])  \n",
    "axes[0,0].set_title('Revenue by Season')  \n",
    "axes[0,0].set_ylabel('Total Revenue ($)')  \n",
    "\n",
    "# Transactions by day of week  \n",
    "dow_transactions = transactions_fe.groupby('day_of_week')['transaction_id'].count()  \n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']  \n",
    "axes[0,1].bar(day_names, dow_transactions.values, color='skyblue')  \n",
    "axes[0,1].set_title('Transactions by Day of Week')  \n",
    "axes[0,1].set_ylabel('Number of Transactions')  \n",
    "\n",
    "# Revenue by holiday period  \n",
    "holiday_revenue = transactions_fe.groupby('holiday_period')['revenue'].sum()  \n",
    "axes[1,0].pie(holiday_revenue.values, labels=holiday_revenue.index, autopct='%1.1f%%')  \n",
    "axes[1,0].set_title('Revenue Distribution: Holiday vs Regular')  \n",
    "\n",
    "# Transactions by time of day  \n",
    "tod_transactions = transactions_fe.groupby('time_of_day')['transaction_id'].count()  \n",
    "axes[1,1].bar(tod_transactions.index, tod_transactions.values, color=['navy', 'blue', 'lightblue', 'skyblue'])  \n",
    "axes[1,1].set_title('Transactions by Time of Day')  \n",
    "axes[1,1].set_ylabel('Number of Transactions')  \n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()\n",
    "## 2. Customer Behavioral Features\"\n",
    "print(\"ğŸ‘¥ CUSTOMER BEHAVIORAL FEATURE ENGINEERING\")  \n",
    "print(\"=\" * 50)  \n",
    "   \n",
    "# Calculate customer-level features  \n",
    "customer_features = transactions_fe.groupby('customer_id').agg({  \n",
    "    'revenue': ['sum', 'mean', 'std', 'count'],  \n",
    "    'quantity': ['sum', 'mean', 'std'],  \n",
    "    'date': ['min', 'max', 'nunique'],  \n",
    "    'product_id': 'nunique',  \n",
    "    'category': 'nunique'  \n",
    "    }).round(2)  \n",
    "   \n",
    "# Flatten column names  \n",
    "customer_features.columns = [  \n",
    "    'total_revenue', 'avg_revenue', 'std_revenue', 'transaction_count',  \n",
    "    'total_quantity', 'avg_quantity', 'std_quantity',  \n",
    "    'first_purchase', 'last_purchase', 'unique_days',  \n",
    "    'unique_products', 'unique_categories'\n",
    "    ]  \n",
    "   \n",
    "customer_features = customer_features.reset_index()  \n",
    "   \n",
    "# Calculate additional customer metrics  \n",
    "latest_date = transactions_fe['date'].max()  \n",
    "customer_features['customer_lifetime_days'] = (latest_date - customer_features['first_purchase']).dt.days  \n",
    "customer_features['days_since_last_purchase'] = (latest_date - customer_features['last_purchase']).dt.days  \n",
    "customer_features['purchase_frequency'] = customer_features['transaction_count'] / customer_features['customer_lifetime_days']  \n",
    "customer_features['avg_days_between_purchases'] = customer_features['customer_lifetime_days'] / customer_features['transaction_count']  \n",
    "\n",
    "# RFM Scoring  \n",
    "customer_features['recency_score'] = pd.qcut(customer_features['days_since_last_purchase'], 5, labels=[5, 4, 3, 2, 1])  \n",
    "customer_features['frequency_score'] = pd.qcut(customer_features['transaction_count'], 5, labels=[1, 2, 3, 4, 5])  \n",
    "customer_features['monetary_score'] = pd.qcut(customer_features['total_revenue'], 5, labels=[1, 2, 3, 4, 5])  \n",
    "customer_features['rfm_score'] = (  \n",
    "    customer_features['recency_score'].astype(str) +   \n",
    "    customer_features['frequency_score'].astype(str) +   \n",
    "    customer_features['monetary_score'].astype(str)  \n",
    "    )  \n",
    "\n",
    "# Customer segmentation based on RFM  \n",
    "def segment_customer(row):  \n",
    "    r, f, m = row['recency_score'], row['frequency_score'], row['monetary_score']  \n",
    "    \n",
    "    if r >= 4 and f >= 4 and m >= 4:  \n",
    "        return 'Champions'  \n",
    "    elif r >= 3 and f >= 3 and m >= 3:  \n",
    "        return 'Loyal Customers'  \n",
    "    elif r >= 4 and f <= 2:  \n",
    "        return 'New Customers'  \n",
    "    elif r >= 2 and f >= 2:  \n",
    "        return 'Potential Loyalists'  \n",
    "    elif r <= 2 and f >= 3:  \n",
    "        return 'At Risk'  \n",
    "    elif r <= 2 and f <= 2:  \n",
    "        return 'Lost Customers'  \n",
    "    else:  \n",
    "        return 'Regular Customers'  \n",
    "    \n",
    "customer_features['customer_segment'] = customer_features.apply(segment_customer, axis=1)  \n",
    "\n",
    "# Customer value tier  \n",
    "customer_features['value_tier'] = pd.qcut(customer_features['total_revenue'],   \n",
    "                                         q=4,   \n",
    "                                         labels=['Bronze', 'Silver', 'Gold', 'Platinum'])  \n",
    "   \n",
    "print(\"âœ… Customer behavioral features created:\")  \n",
    "print(f\"   â€¢ Basic spending metrics (total, average, std)\")  \n",
    "print(f\"   â€¢ Purchase frequency and recency\")  \n",
    "print(f\"   â€¢ Product and category diversity\")  \n",
    "print(f\"   â€¢ RFM scoring and segmentation\")  \n",
    "print(f\"   â€¢ Customer value tiers\")  \n",
    "print(f\" ğŸ“Š Customer Segments Distribution:\")  \n",
    "print(customer_features['customer_segment'].value_counts())\n",
    "# Visualize customer segments  \n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))  \n",
    " \n",
    "# Customer segments distribution  \n",
    "segment_dist = customer_features['customer_segment'].value_counts()  \n",
    "axes[0,0].pie(segment_dist.values, labels=segment_dist.index, autopct='%1.1f%%', startangle=90)  \n",
    "axes[0,0].set_title('Customer Segments Distribution')  \n",
    "\n",
    "# Average revenue by segment  \n",
    "segment_revenue = customer_features.groupby('customer_segment')['total_revenue'].mean().sort_values(ascending=False)  \n",
    "axes[0,1].bar(segment_revenue.index, segment_revenue.values, color='lightgreen')  \n",
    "axes[0,1].set_title('Average Revenue by Customer Segment')  \n",
    "axes[0,1].set_ylabel('Average Revenue ($)')  \n",
    "axes[0,1].tick_params(axis='x', rotation=45)  \n",
    " \n",
    "# Purchase frequency by segment  \n",
    "segment_frequency = customer_features.groupby('customer_segment')['purchase_frequency'].mean().sort_values(ascending=False)  \n",
    "axes[1,0].bar(segment_frequency.index, segment_frequency.values, color='lightcoral')  \n",
    "axes[1,0].set_title('Average Purchase Frequency by Segment')  \n",
    "axes[1,0].set_ylabel('Purchases per Day')  \n",
    "axes[1,0].tick_params(axis='x', rotation=45)  \n",
    " \n",
    "# Customer lifetime by segment  \n",
    "segment_lifetime = customer_features.groupby('customer_segment')['customer_lifetime_days'].mean().sort_values(ascending=False)  \n",
    "axes[1,1].bar(segment_lifetime.index, segment_lifetime.values, color='gold')  \n",
    "axes[1,1].set_title('Average Customer Lifetime by Segment')  \n",
    "axes[1,1].set_ylabel('Lifetime (Days)')  \n",
    "axes[1,1].tick_params(axis='x', rotation=45)  \n",
    " \n",
    "plt.tight_layout()  \n",
    "plt.show()  \n",
    "## 3. Product Feature Engineering\"\n",
    "print(\"ğŸ“¦ PRODUCT FEATURE ENGINEERING\")  \n",
    "print(\"=\" * 50)  \n",
    " \n",
    "# Product performance features  \n",
    "product_features = transactions_fe.groupby('product_id').agg({  \n",
    "    'revenue': ['sum', 'mean', 'std', 'count'],  \n",
    "    'quantity': ['sum', 'mean', 'std'],  \n",
    "    'profit': ['sum', 'mean'],  \n",
    "    'customer_id': 'nunique',  \n",
    "    'date': ['min', 'max', 'nunique']  \n",
    "    }).round(2)  \n",
    "     \n",
    "# Flatten column names  \n",
    "product_features.columns = [  \n",
    "    'total_revenue', 'avg_revenue_per_tx', 'std_revenue', 'transaction_count',  \n",
    "    'total_quantity', 'avg_quantity_per_tx', 'std_quantity',  \n",
    "    'total_profit', 'avg_profit_per_tx',  \n",
    "    'unique_customers',  \n",
    "    'first_sale', 'last_sale', 'unique_sale_days'  \n",
    "    ]  \n",
    "     \n",
    "product_features = product_features.reset_index()  \n",
    "    \n",
    "# Merge with product master data  \n",
    "product_features = product_features.merge(  \n",
    "    products[['product_id', 'product_name', 'category', 'price', 'price_segment', 'profit_margin']],  \n",
    "    on='product_id',  \n",
    "    how='left'  \n",
    "    )  \n",
    "      \n",
    "# Calculate additional product metrics  \n",
    "product_features['product_lifetime_days'] = (latest_date - product_features['first_sale']).dt.days  \n",
    "product_features['sales_velocity'] = product_features['total_quantity'] / product_features['product_lifetime_days']  \n",
    "product_features['customer_penetration_rate'] = product_features['unique_customers'] / len(customer_features)  \n",
    "product_features['avg_days_between_sales'] = product_features['product_lifetime_days'] / product_features['transaction_count']  \n",
    "product_features['profit_margin_actual'] = (product_features['total_profit'] / product_features['total_revenue']) * 100  \n",
    " \n",
    "# Product popularity score  \n",
    "product_features['popularity_score'] = (  \n",
    "    product_features['total_quantity'] / product_features['total_quantity'].max() * 0.4 +  \n",
    "    product_features['unique_customers'] / product_features['unique_customers'].max() * 0.3 +  \n",
    "    product_features['transaction_count'] / product_features['transaction_count'].max() * 0.3  \n",
    "    ) * 100  \n",
    "     \n",
    "# Product performance tier  \n",
    "product_features['performance_tier'] = pd.qcut(product_features['total_revenue'],   \n",
    "                                              q=4,   \n",
    "                                              labels=['Low', 'Medium', 'High', 'Premium'])  \n",
    " \n",
    "# Seasonality indicator (simplified)  \n",
    "product_seasonality = transactions_fe.groupby(['product_id', 'season'])['quantity'].sum().unstack(fill_value=0)  \n",
    "product_seasonality['seasonality_score'] = product_seasonality.std(axis=1) / product_seasonality.mean(axis=1)  \n",
    "product_features = product_features.merge(  \n",
    "    product_seasonality[['seasonality_score']],   \n",
    "    on='product_id',   \n",
    "    how='left'  \n",
    "    )  \n",
    "     \n",
    "print(\"âœ… Product features created:\")  \n",
    "print(f\"   â€¢ Sales performance metrics\")  \n",
    "print(f\"   â€¢ Customer reach and penetration\")  \n",
    "print(f\"   â€¢ Sales velocity and frequency\")  \n",
    "print(f\"   â€¢ Profitability analysis\")  \n",
    "print(f\"   â€¢ Popularity scoring\")  \n",
    "print(f\"   â€¢ Performance tier classification\")  \n",
    "print(f\"   â€¢ Seasonality patterns\")  \n",
    "print(f\"ğŸ“Š Top 10 Products by Popularity Score:\")  \n",
    "top_products = product_features.nlargest(10, 'popularity_score')[['product_name', 'category', 'popularity_score', 'total_revenue']]  \n",
    "display(top_products)\n",
    "## 4. Transactional & Basket Analysis Features\"\n",
    "print(\"ğŸ›’ TRANSACTIONAL & BASKET ANALYSIS FEATURES\")  \n",
    "print(\"=\" * 50)  \n",
    " \n",
    "# Transaction-level features  \n",
    "transaction_features = transactions_fe.groupby('transaction_id').agg({  \n",
    "    'quantity': 'sum',  \n",
    "    'revenue': 'sum',  \n",
    "    'profit': 'sum',  \n",
    "    'product_id': 'count',  \n",
    "    'category': 'nunique'  \n",
    "    }).round(2)  \n",
    "     \n",
    "transaction_features.columns = [  \n",
    "    'basket_size', 'basket_value', 'basket_profit',   \n",
    "    'unique_products', 'unique_categories'  \n",
    "]  \n",
    "    \n",
    "transaction_features = transaction_features.reset_index()  \n",
    "    \n",
    "# Merge back with transaction details  \n",
    "transaction_features = transaction_features.merge(  \n",
    "    transactions_fe[['transaction_id', 'customer_id', 'date', 'region', 'customer_tier']].drop_duplicates(),  \n",
    "    on='transaction_id',  \n",
    "    how='left'  \n",
    ")  \n",
    "\n",
    "# Calculate basket metrics  \n",
    "transaction_features['avg_product_value'] = transaction_features['basket_value'] / transaction_features['unique_products']  \n",
    "transaction_features['basket_efficiency'] = transaction_features['basket_profit'] / transaction_features['basket_value']  \n",
    "transaction_features['category_diversity'] = transaction_features['unique_categories'] / transaction_features['unique_products']  \n",
    "\n",
    "# Basket type classification  \n",
    "def classify_basket(row):  \n",
    "    if row['unique_products'] == 1:  \n",
    "        return 'Single Item'  \n",
    "    elif row['unique_products'] <= 3:  \n",
    "        return 'Small Basket'  \n",
    "    elif row['unique_products'] <= 6:  \n",
    "        return 'Medium Basket'  \n",
    "    else:  \n",
    "        return 'Large Basket'  \n",
    "\n",
    "transaction_features['basket_type'] = transaction_features.apply(classify_basket, axis=1)  \n",
    "\n",
    "# Value-based basket classification  \n",
    "transaction_features['value_segment'] = pd.qcut(transaction_features['basket_value'],   \n",
    "                                                   q=4,   \n",
    "                                                   labels=['Low Value', 'Medium Value', 'High Value', 'Premium Value'])  \n",
    "\n",
    "# Cross-selling opportunities (simplified)  \n",
    "# For each transaction, identify if it contains products from multiple categories  \n",
    "transaction_features['is_cross_category'] = transaction_features['unique_categories'] > 1  \n",
    "\n",
    "print(\"âœ… Transactional features created:\")  \n",
    "print(f\"   â€¢ Basket size and value metrics\")  \n",
    "print(f\"   â€¢ Product and category diversity\")  \n",
    "print(f\"   â€¢ Basket efficiency (profitability)\")  \n",
    "print(f\"   â€¢ Basket type classification\")  \n",
    "print(f\"   â€¢ Value-based segmentation\")  \n",
    "print(f\"   â€¢ Cross-category purchase indicators\")  \n",
    "print(f\"ğŸ“Š Basket Analysis Summary:\")  \n",
    "basket_summary = transaction_features.groupby('basket_type').agg({  \n",
    "    'transaction_id': 'count',  \n",
    "    'basket_value': 'mean',  \n",
    "    'basket_size': 'mean',  \n",
    "    'basket_efficiency': 'mean'  \n",
    "    }).round(2)  \n",
    "    \n",
    "basket_summary.columns = ['transaction_count', 'avg_basket_value', 'avg_basket_size', 'avg_efficiency']  \n",
    "display(basket_summary)\n",
    "## 5. Geographic Feature Engineering\"\n",
    "print(\"ğŸŒ GEOGRAPHIC FEATURE ENGINEERING\")  \n",
    "print(\"=\" * 50)  \n",
    " \n",
    "# Regional performance features  \n",
    "regional_features = transactions_fe.groupby('region').agg({  \n",
    "    'revenue': ['sum', 'mean', 'std'],  \n",
    "    'profit': ['sum', 'mean'],  \n",
    "    'transaction_id': 'count',  \n",
    "    'customer_id': 'nunique',  \n",
    "    'quantity': 'sum'  \n",
    "    }).round(2)  \n",
    "     \n",
    "# Flatten column names  \n",
    "regional_features.columns = [  \n",
    "    'total_revenue', 'avg_revenue_per_tx', 'std_revenue',  \n",
    "    'total_profit', 'avg_profit_per_tx',  \n",
    "    'transaction_count',  \n",
    "    'unique_customers',  \n",
    "    'total_quantity'  \n",
    "]  \n",
    "\n",
    "regional_features = regional_features.reset_index()  \n",
    " \n",
    "# Calculate regional metrics  \n",
    "total_customers = len(customer_features)  \n",
    "total_revenue = regional_features['total_revenue'].sum()  \n",
    "\n",
    "regional_features['market_share'] = (regional_features['total_revenue'] / total_revenue) * 100  \n",
    "regional_features['customer_penetration'] = (regional_features['unique_customers'] / total_customers) * 100  \n",
    "regional_features['revenue_per_customer'] = regional_features['total_revenue'] / regional_features['unique_customers']  \n",
    "regional_features['transactions_per_customer'] = regional_features['transaction_count'] / regional_features['unique_customers']  \n",
    "regional_features['avg_transaction_value'] = regional_features['total_revenue'] / regional_features['transaction_count']  \n",
    "\n",
    "# Regional performance tier  \n",
    "regional_features['performance_tier'] = pd.qcut(regional_features['total_revenue'],   \n",
    "    q=3,   \n",
    "    labels=['Low', 'Medium', 'High'])  \n",
    "   \n",
    "# Regional efficiency score  \n",
    "regional_features['efficiency_score'] = (  \n",
    "    regional_features['market_share'] / regional_features['market_share'].max() * 0.4 +  \n",
    "    regional_features['revenue_per_customer'] / regional_features['revenue_per_customer'].max() * 0.3 +  \n",
    "    regional_features['customer_penetration'] / regional_features['customer_penetration'].max() * 0.3  \n",
    "    ) * 100  \n",
    "    \n",
    "print(\"âœ… Geographic features created:\")  \n",
    "print(f\"   â€¢ Regional sales performance\")  \n",
    "print(f\"   â€¢ Market share and penetration\")  \n",
    "print(f\"   â€¢ Customer value metrics\")  \n",
    "print(f\"   â€¢ Performance tier classification\")  \n",
    "print(f\"   â€¢ Regional efficiency scoring\")  \n",
    "print(f\"ğŸ“Š Regional Performance Summary:\")  \n",
    "display(regional_features.sort_values('efficiency_score', ascending=False))\n",
    "## 6. Advanced ML Features & Feature Selection\"\n",
    "print(\"ğŸ¤– ADVANCED ML FEATURES & FEATURE SELECTION\")  \n",
    "print(\"=\" * 50)  \n",
    " \n",
    "# Create a comprehensive feature set for machine learning  \n",
    "# We'll create features at customer level for prediction tasks  \n",
    " \n",
    "# Start with customer features  \n",
    "ml_features = customer_features.copy()  \n",
    " \n",
    "# Add temporal behavior features  \n",
    "customer_temporal = transactions_fe.groupby('customer_id').agg({  \n",
    "    'day_of_week': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 0,  # Most frequent purchase day  \n",
    "        'season': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown',  # Most frequent season  \n",
    "        'is_weekend': 'mean',  # Weekend purchase ratio  \n",
    "        'hour': ['mean', 'std']  # Purchase time patterns  \n",
    "    }).round(2)  \n",
    "     \n",
    "customer_temporal.columns = ['preferred_day', 'preferred_season', 'weekend_ratio', 'avg_purchase_hour', 'std_purchase_hour']  \n",
    "customer_temporal = customer_temporal.reset_index()  \n",
    "    \n",
    "ml_features = ml_features.merge(customer_temporal, on='customer_id', how='left')  \n",
    "    \n",
    "# Add product preference features  \n",
    "customer_preferences = transactions_fe.groupby('customer_id').agg({  \n",
    "    'category': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown',  # Favorite category  \n",
    "    'price_segment': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown',  # Preferred price segment  \n",
    "    'profit_margin': 'mean'  # Average margin of purchased products  \n",
    "    }).round(2)  \n",
    "    \n",
    "customer_preferences.columns = ['preferred_category', 'preferred_price_segment', 'avg_product_margin']  \n",
    "customer_preferences = customer_preferences.reset_index()  \n",
    "    \n",
    "ml_features = ml_features.merge(customer_preferences, on='customer_id', how='left')  \n",
    "    \n",
    "# Add regional features  \n",
    "customer_region = transactions_fe.groupby('customer_id').agg({  \n",
    "    'region': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown'  # Primary region  \n",
    "    })  \n",
    "customer_region.columns = ['primary_region']  \n",
    "customer_region = customer_region.reset_index()  \n",
    "    \n",
    "ml_features = ml_features.merge(customer_region, on='customer_id', how='left')  \n",
    "    \n",
    "# Add basket behavior features  \n",
    "customer_basket = transaction_features.groupby('customer_id').agg({  \n",
    "    'basket_value': ['mean', 'std', 'max'],  \n",
    "    'basket_size': ['mean', 'std'],  \n",
    "    'basket_efficiency': 'mean',  \n",
    "    'is_cross_category': 'mean'  \n",
    "    }).round(2)  \n",
    "    \n",
    "customer_basket.columns = [  \n",
    "    'avg_basket_value', 'std_basket_value', 'max_basket_value',  \n",
    "    'avg_basket_size', 'std_basket_size',  \n",
    "    'avg_basket_efficiency',  \n",
    "    'cross_category_ratio'  \n",
    "]  \n",
    "customer_basket = customer_basket.reset_index()  \n",
    "    \n",
    "ml_features = ml_features.merge(customer_basket, on='customer_id', how='left')  \n",
    "    \n",
    "# Create target variable for predictive modeling (e.g., high-value customer)  \n",
    "ml_features['is_high_value'] = (ml_features['total_revenue'] > ml_features['total_revenue'].quantile(0.75)).astype(int)  \n",
    "    \n",
    "# Create churn risk indicator (customers with no recent purchases)  \n",
    "ml_features['churn_risk'] = (ml_features['days_since_last_purchase'] > 90).astype(int)  \n",
    "    \n",
    "print(\"âœ… Advanced ML features created:\")  \n",
    "print(f\"   â€¢ Temporal behavior patterns\")  \n",
    "print(f\"   â€¢ Product preferences\")  \n",
    "print(f\"   â€¢ Regional patterns\")  \n",
    "print(f\"   â€¢ Basket behavior metrics\")  \n",
    "print(f\"   â€¢ Target variables for ML\")  \n",
    "print(f\"   â€¢ Churn risk indicators\")  \n",
    "print(f\"ğŸ“Š ML Dataset Shape: {ml_features.shape}\")  \n",
    "print(f\"ğŸ“Š High-value customers: {ml_features['is_high_value'].sum()} ({ml_features['is_high_value'].mean()*100:.1f}%)\")  \n",
    "print(f\"ğŸ“Š At-risk customers: {ml_features['churn_risk'].sum()} ({ml_features['churn_risk'].mean()*100:.1f}%)\")\n",
    "# Feature importance analysis  \n",
    "print(\"ğŸ¯ FEATURE IMPORTANCE ANALYSIS\")  \n",
    "print(\"=\" * 50)  \n",
    " \n",
    "# Select numerical features for importance analysis  \n",
    "numerical_features = ml_features.select_dtypes(include=[np.number]).columns.tolist()  \n",
    "# Remove target variables and ID columns  \n",
    "numerical_features = [f for f in numerical_features if f not in ['customer_id', 'is_high_value', 'churn_risk', 'recency_score', 'frequency_score', 'monetary_score']]  \n",
    "# Prepare data for feature importance  \n",
    "X = ml_features[numerical_features].fillna(0)  \n",
    "y = ml_features['is_high_value']  \n",
    "# Calculate feature importance using correlation  \n",
    "feature_importance = []  \n",
    "for feature in numerical_features:  \n",
    "    correlation = np.corrcoef(X[feature], y)[0, 1]  \n",
    "    feature_importance.append((feature, abs(correlation)))  \n",
    "  \n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)  \n",
    "  \n",
    "print(\"ğŸ“ˆ Top 15 Most Important Features for High-Value Customer Prediction:\")  \n",
    "top_features = feature_importance[:15]  \n",
    "  \n",
    "fig, ax = plt.subplots(figsize=(12, 8))  \n",
    "features, importance = zip(*top_features)  \n",
    "y_pos = np.arange(len(features))  \n",
    "ax.barh(y_pos, importance, color='skyblue')  \n",
    "ax.set_yticks(y_pos)  \n",
    "ax.set_yticklabels(features)  \n",
    "ax.invert_yaxis()  \n",
    "ax.set_xlabel('Absolute Correlation with High-Value Customer')  \n",
    "ax.set_title('Feature Importance for Customer Value Prediction')  \n",
    " \n",
    "plt.tight_layout()  \n",
    "plt.show()  \n",
    " \n",
    "# Display top features  \n",
    "top_features_df = pd.DataFrame(top_features, columns=['Feature', 'Correlation'])  \n",
    "display(top_features_df)\n",
    "## 7. Feature Validation & Export\"\n",
    "print(\"ğŸ’¾ FEATURE VALIDATION & EXPORT\")  \n",
    "print(\"=\" * 50)  \n",
    " \n",
    "# Data quality check  \n",
    "print(\"ğŸ” Data Quality Check:\")  \n",
    "print(f\"â€¢ ML Features shape: {ml_features.shape}\")  \n",
    "print(f\"â€¢ Missing values: {ml_features.isnull().sum().sum()}\")  \n",
    "print(f\"â€¢ Duplicate rows: {ml_features.duplicated().sum()}\")  \n",
    " \n",
    "# Check feature distributions  \n",
    "print(f\"ğŸ“Š Feature Distributions Summary:\")  \n",
    "numeric_summary = ml_features[numerical_features].describe()  \n",
    "print(numeric_summary.loc[['mean', 'std', 'min', 'max']].T.head(10))  \n",
    " \n",
    "# Save engineered features  \n",
    "print(\"ğŸ’¾ Saving engineered features...\")  \n",
    "customer_features.to_csv('../data/processed/customer_features_engineered.csv', index=False)  \n",
    "product_features.to_csv('../data/processed/product_features_engineered.csv', index=False)  \n",
    "transaction_features.to_csv('../data/processed/transaction_features_engineered.csv', index=False)  \n",
    "regional_features.to_csv('../data/processed/regional_features_engineered.csv', index=False)  \n",
    "ml_features.to_csv('../data/processed/ml_ready_features.csv', index=False)  \n",
    "\n",
    "feature_importance_df = pd.DataFrame(feature_importance, columns=['feature', 'importance'])  \n",
    "feature_importance_df.to_csv('../data/processed/feature_importance.csv', index=False)  \n",
    "\n",
    "print(\"âœ… All engineered features saved to data/processed/\")  \n",
    "\n",
    "# Create feature documentation  \n",
    "feature_docs = {  \n",
    "    'customer_features': 'Customer behavioral and RFM features',  \n",
    "    'product_features': 'Product performance and popularity features',  \n",
    "    'transaction_features': 'Basket analysis and transaction patterns',  \n",
    "    'regional_features': 'Geographic performance metrics',  \n",
    "    'ml_ready_features': 'Comprehensive features for machine learning',  \n",
    "    'feature_importance': 'Feature importance rankings'  \n",
    "}  \n",
    "\n",
    "feature_docs_df = pd.DataFrame(list(feature_docs.items()), columns=['feature_set', 'description'])  \n",
    "feature_docs_df.to_csv('../data/processed/feature_documentation.csv', index=False)  \n",
    "print(\"ğŸ‰ FEATURE ENGINEERING COMPLETED SUCCESSFULLY!\")  \n",
    "print(\"=\" * 60)  \n",
    "print(\"ğŸ“š Feature Sets Created:\")  \n",
    "for feature_set, description in feature_docs.items():  \n",
    "    print(f\"   â€¢ {feature_set}: {description}\")  \n",
    " \n",
    "print(f\"ğŸš€ Next Steps:\")  \n",
    "print(\"â€¢ Use ml_ready_features.csv for machine learning models\")  \n",
    "print(\"â€¢ Build predictive models for customer value and churn\")  \n",
    "print(\"â€¢ Create segmentation models using engineered features\")  \n",
    "print(\"â€¢ Integrate features into the Streamlit dashboard\")  \n",
    "print(\"â€¢ Use feature importance for business decision making\")  \n",
    "print(\"ğŸ’¡ Business Applications:\")  \n",
    "print(\"â€¢ High-value customer identification\")  \n",
    "print(\"â€¢ Churn prediction and prevention\")  \n",
    "print(\"â€¢ Product recommendation systems\")  \n",
    "print(\"â€¢ Regional expansion strategies\")\n",
    "print(\"â€¢ Personalized marketing campaigns\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
